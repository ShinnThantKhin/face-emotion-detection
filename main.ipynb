{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91e79b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import asyncio\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55f59b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load face\n",
    "try:\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "except Exception:\n",
    "    st.write(\"Error loading cascade classifiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17aaa06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the labels for the emotions\n",
    "emotions= {0: \"Angry\", 1: \"Disgust\", 2: \"Fear\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprise\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5872976f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load json and create model\n",
    "json_file = open('model/emotion_detection_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7902e1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "# Load into new model\n",
    "model.load_weights('model/emotion_detection_model.h5')\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ec576d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to measure response time\n",
    "# Start time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99243c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect faces and emotions in an image\n",
    "#def detect_faces_and_emotions(image):\n",
    "#    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "#    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "#\n",
    "#    for (x, y, w, h) in faces:\n",
    "#        cv2.rectangle(image, (x, y-50), (x+w, y+h+10), (0, 255, 0), 6)\n",
    "#        roi_frame = gray[y:y + h, x:x + w]\n",
    "#        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_frame, (48, 48)), -1), 0)\n",
    "\n",
    "        # Predict the emotion of the face using the pre-trained model\n",
    "#        emotion_prediction = model.predict(cropped_img)\n",
    "#        max_index = int(np.argmax(emotion_prediction))\n",
    "#        cv2.putText(image, emotions[max_index], (x+5, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "#    return image\n",
    "\n",
    "def detect_faces_and_emotions(image):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(image, (x, y-50), (x+w, y+h+10), (0, 255, 0), 6)\n",
    "        roi_frame = gray[y:y + h, x:x + w]\n",
    "        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_frame, (48, 48)), -1), 0)\n",
    "\n",
    "        # Predict the emotion of the face using the pre-trained model\n",
    "        emotion_prediction = model.predict(cropped_img)\n",
    "        max_index = int(np.argmax(emotion_prediction))\n",
    "        \n",
    "        # Calculate the coordinates for placing the text below the rectangle\n",
    "        text_x = x + 5\n",
    "        text_y = y + h + 10\n",
    "        \n",
    "        # Put the emotion text below and outside the rectangle\n",
    "        cv2.putText(image, emotions[max_index], (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8b6b81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-07 15:35:46.519 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run D:\\ProgramforCS\\ANACONDA\\envs\\Machine_Learning\\lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n"
     ]
    }
   ],
   "source": [
    "# Streamlit app\n",
    "st.title(\"Face  &  Emotion Detection\")\n",
    "\n",
    "st.sidebar.caption(\"Upload an image to detected!\")\n",
    "uploaded_file = st.sidebar.file_uploader(\"Choose an image...\", type=[\"jpg\", \"jpeg\", \"png\", \"svg\", \"gif\"])\n",
    "\n",
    "if uploaded_file is not None:\n",
    "    image = np.array(bytearray(uploaded_file.read()), dtype=np.uint8)\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "\n",
    "    st.write(\"Original Image\")\n",
    "    st.image(image, channels=\"BGR\")\n",
    "\n",
    "    detected_image = detect_faces_and_emotions(image)\n",
    "\n",
    "    st.write(\"Detected Image\")\n",
    "    st.image(detected_image, channels=\"BGR\")\n",
    "\n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50c7398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End time\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f502e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate response time\n",
    "response_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865903b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the response time\n",
    "print(\"Response time:\", response_time, \"seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
